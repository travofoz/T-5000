# --- LLM Provider API Keys ---
# Obtain keys from the respective provider websites.
# Leave blank if not using the provider or if using alternative auth (e.g., Azure AD for OpenAI).
GEMINI_API_KEY=YOUR_GEMINI_API_KEY_HERE
OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE
ANTHROPIC_API_KEY=YOUR_ANTHROPIC_API_KEY_HERE

# --- LLM Provider Base URLs (Optional Overrides) ---
# Primarily for OpenAI-compatible endpoints (like local models) or self-hosted Ollama.
# OPENAI_BASE_URL=http://localhost:8000/v1
OLLAMA_BASE_URL=http://localhost:11434 # Default if running Ollama locally

# --- Model Name Overrides (Optional) ---
# Override default models defined in config/settings.py. Use provider-specific model names.
# CONTROLLER_AGENT_MODEL=gemini-1.5-flash-latest
# CODING_AGENT_MODEL=gpt-4o
# SYSADMIN_AGENT_MODEL=claude-3-sonnet-20240229
# OLLAMA_MODEL=llama3:latest # Default model for OllamaProvider if used

# --- Tool Configuration ---
# Comma-separated list of tool names that require user confirmation before execution.
# Example: HIGH_RISK_TOOLS=run_shell_command,run_sudo_command,edit_file
# Setting to an empty value (e.g., HIGH_RISK_TOOLS=) disables confirmations (EXTREME RISK).
HIGH_RISK_TOOLS=run_shell_command,run_sudo_command,apt_command,yum_command,systemctl_command,kill_process,edit_file,esptool_command,openocd_command,ssh_command,scp_command,gdb_mi_command,nmap_scan,sqlmap_scan,nikto_scan,msfvenom_generate,gobuster_scan,make_command,gcc_compile

# Default timeout for external commands executed by tools (in seconds).
DEFAULT_COMMAND_TIMEOUT=120

# --- Cost/Token Quota Monitoring (Optional) ---
# Approximate token limits. Set to 0 or omit to disable.
MAX_GLOBAL_TOKENS=1000000
WARN_TOKEN_THRESHOLD=800000 # Warn when usage exceeds this percentage of MAX_GLOBAL_TOKENS (e.g., 80% of 1M)

# --- Agent State ---
# Directory where agent history/state files will be saved.
# AGENT_STATE_DIR=./agent_state # Default set in settings.py

# --- Logging Level ---
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# LOG_LEVEL=INFO
